{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "puthon.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SupreetRonad/Ode-to-Code/blob/main/puthon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQJ6K1jjCXE6",
        "outputId": "36cb60ce-a43b-485f-efb2-e1ab64ed6b24"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 1s (4,398 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/e6/a4e9fc8a93c1318540e8de6d8d4beb5749b7960388a7c7f27799fc2dd016/pytesseract-0.3.7.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.7-py2.py3-none-any.whl size=13953 sha256=5a391597aab8003170aa3a399de9140cb290eae04f6e296443356e282c323d10\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/20/7e/1dd0daad1575d5260916bb1e9781246430647adaef4b3ca3b3\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDN9uMWJRRJM"
      },
      "source": [
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbTImyeBBqIo"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "    \n",
        "import string\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def clean_text(text):\n",
        "    # lower text\n",
        "    text = text.lower()\n",
        "    # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # remove words that contain numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    # remove stop words\n",
        "    stop = stopwords.words('english')\n",
        "    text = [x for x in text if x not in stop]\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # pos tag text\n",
        "    pos_tags = pos_tag(text)\n",
        "    # lemmatize text\n",
        "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
        "    # remove words with only one letter\n",
        "    text = [t for t in text if len(t) > 1]\n",
        "    # join all\n",
        "    text = \" \".join(text)\n",
        "    return(text)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkaQUdv6fPdk"
      },
      "source": [
        "#obtained using ml model\n",
        "my_weights ={\n",
        "    'acute': 2,\n",
        "    'shortness': 4,\n",
        "    'fall': 4, 'died': 2, 'rash': 2, 'packed': 2, 'skin': 4, 'or': 0, 'condition': 6, 'ptx': 4, 'nosocomial': 2, 'rupture': 4, 'GPLA': 4, 'aspiration': 2, 'oversedation': 4, 'somnolent': 4, 'perforation': 4, 'surgery': 8, 'time': 10, 'nsicu': 4, 'hemorrhage': 4, 'heel': 6, 'sepsis': 4, 'consultations': 8, 'wound': 6, 'Past': 4, 'deep': 2, 'decubitus': 2, 'overload': 2, 'hyperkalemia': 4, 'pneumonia': 4, 'x-ray': 6, 'number': 6, 'failure': 4, 'diagnosis': 10, 'medicine': 2, 'decubiti': 2, 'hypoglycemia': 4, 'dissection': 6, 'room': 8, 'operating': 6, 'gender': 8, 'od': 2, 'ccu': 4, 'clostridium': 4, 'wet': 2, 'Health': 10, 'error': 0, 'mistakenly': 0, 'consult': 8, 'resuscitation': 4, 'reopen': 0, 'fell': 0, 'eruption': 4, 'Diet': 4, 'transferred': 0, 'next': 0, 'rbc': 4, 'delirium': 4, 'Investigation': 6, 'subtherapeutic': 6, 'tube': 4, 'icu': 6, 'transfer': 0, 'chest': 4, 'Attending': 4, 'infection': 6, 'required': 0, 'hyperglycemia': 4, 'dka': 2, 'vein': 6, 'distress': 4, 'signature': 10, 'admission': 10, 'reaction': 6, 'physician': 10, 'Date': 10, 'fluids': 6, 'family': 6, 'of': 0, 'Reason': 4, 'findings': 0, 'renal': 2, 'lethargic': 2, 'mistake': 0, 'complicated': 4, 'drug': 6, 'birth': 8, 'maternity': 4, '\\ufeffdischarge': 10, 'allergic': 6, 'sedated': 4, 'accident': 6, 'acquired': 0, 'after': 4, 'Wound': 6, 'post': 6, 'op': 6, 'pneumothorax': 4, 'supratherapeutic': 4, 'MLC': 2, 'ICU': 6, 'treatment': 10, 'drop': 0, 'agitation': 2, 'ulcer': 4, 'hospital': 10, 'respiratory': 4, 'desaturation': 4, 'dropped': 0, 'identifier': 0, 'ward': 10, 'laceration': 2, 'sugars': 4, 'overdose': 6, 'history': 8, 'death': 2, 'summary': 10, 'breath': 4, 'Method': 4, 'referral': 4, 'operation': 6, 'Unit': 4, 'volume': 0, 'hematoma': 4, 'contact': 8, 'status': 6, 'difficile': 2, 'age': 10, 'telemetry': 2, 'bed': 10, 'transfusion': 4, 'Patient': 10, 'blood': 6, 'hypoxia': 4, 'Provided': 0, 'hospitalization': 8, 'slipped': 0, 'postoperative': 6, 'FIR': 4, 'complication': 6, 'mental': 4, 'Address': 8, 'expired': 0, 'discontinued': 6, 'syncopy': 4, 'hypotension': 4, 'low': 2, 'Examination': 6, 'nonresponsive': 2, 'reopening': 2, 'pressure': 2, 'line': 2, 'unresponsive': 2, 'Consultant': 8, 'hallucinations': 4, 'micu': 4, 'the': 0, 'Instructions': 4, 'Operating': 6, 'Source': 4, 'fluid': 4, 'iv': 4, 'sore': 4, 'appointment': 6, 'medication': 8, 'admit': 8, 'name': 10, 'polypharmacy': 4, 'Procedures': 4, 'trauma': 4, 'hypoxemia': 4, 'accidentally': 4, 'RTA': 4, 'thrombosis': 4\n",
        "}\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjbyMWmbWQl0",
        "outputId": "b5d0d688-a54f-48f5-f6b3-aab2b2efcc29"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H8o_lTMX4fg"
      },
      "source": [
        "def returnSum(dict1,dict2):\n",
        "      \n",
        "     sum = 0\n",
        "     for i in dict1:\n",
        "           sum = sum + (dict1[i] *dict2[i])\n",
        "        \n",
        "     return sum"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka0tqVDIRUCZ"
      },
      "source": [
        "data_path='/content/drive/MyDrive/project'\n",
        "categories=os.listdir(data_path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aW4ENgmZBqd"
      },
      "source": [
        "final=[]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjWcihyfXHAn",
        "outputId": "56603b15-baad-43a9-cc5a-411392fb9bdd"
      },
      "source": [
        "for category in categories:\n",
        "  folder_path=os.path.join(data_path,category)\n",
        "  img_names=os.listdir(folder_path)\n",
        "        \n",
        "  for img_name in img_names:\n",
        "    img_path=os.path.join(folder_path,img_name)\n",
        "    extractedInformation = pytesseract.image_to_string(Image.open(img_path))\n",
        "    pdf_data=clean_text(extractedInformation).split()\n",
        "    my_file = open(r'/content/my_keywords.txt',\"r\")\n",
        "    k = my_file.read().split()\n",
        "    k = set(k)\n",
        "    dict_keywords={}\n",
        "        \n",
        "    for i in k:\n",
        "      dict_keywords[i]=0\n",
        "        \n",
        "    for i in dict_keywords:\n",
        "      if i in pdf_data:\n",
        "        dict_keywords[i]+=1\n",
        "    final.append(returnSum(dict_keywords,my_weights))\n",
        "print(final)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[108, 106, 12, 76, 110, 88, 28, 96, 68, 50, 88, 138, 64, 102, 128, 74, 68, 74, 106, 22, 16, 10, 16, 12, 16, 20, 40, 10, 24]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfFDgfSEabZG"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "km =KMeans(n_clusters = 2)\n",
        "x=final\n",
        "y=[]\n",
        "for i in range(1,len(x)+1):\n",
        "  y.append(i)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIt7xItbadO7",
        "outputId": "38480791-a9b3-4a3f-c864-f24667247970"
      },
      "source": [
        "import numpy as np\n",
        "combined = np.vstack((x, y)).T\n",
        "km.fit(combined)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRGf3Y8-a_3k",
        "outputId": "5e5215bb-ad41-48eb-b6db-e7a8ed9c6018"
      },
      "source": [
        "y_p = km.fit_predict(combined)\n",
        "\n",
        "for1 = sum([i for i in range(len(x)) if y_p[i] == 1])\n",
        "\n",
        "for0 = sum([i for i in range(len(x)) if y_p[i] == 0])\n",
        "\n",
        "if for1 > for0 : flag = 1\n",
        "else : flag = 0\n",
        "    \n",
        "print(flag)\n",
        "\n",
        "for i in range(len(x)):\n",
        "  print(str(y_p[i])+ \"   \" +str(x[i]))\n",
        "  "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0   108\n",
            "0   106\n",
            "1   12\n",
            "0   76\n",
            "0   110\n",
            "0   88\n",
            "1   28\n",
            "0   96\n",
            "0   68\n",
            "1   50\n",
            "0   88\n",
            "0   138\n",
            "0   64\n",
            "0   102\n",
            "0   128\n",
            "0   74\n",
            "0   68\n",
            "0   74\n",
            "0   106\n",
            "1   22\n",
            "1   16\n",
            "1   10\n",
            "1   16\n",
            "1   12\n",
            "1   16\n",
            "1   20\n",
            "1   40\n",
            "1   10\n",
            "1   24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCbfWPR6hpzZ"
      },
      "source": [
        "# Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFykTPHMhAdP"
      },
      "source": [
        "import base64\n",
        "  \n",
        "  \n",
        "file = open(r'binary.txt', 'r')\n",
        "byte = file.read()\n",
        "file.close()\n",
        "  \n",
        "decodeit = open('input.jpeg', 'wb')\n",
        "decodeit.write(base64.b64decode((byte)))\n",
        "decodeit.close()\n",
        "img_path='/content/input.jpeg'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAfu3VbamvAA",
        "outputId": "b7bd9643-795b-4733-c2c7-196ee92942cc"
      },
      "source": [
        "extractedInformation = pytesseract.image_to_string(Image.open(img_path))\n",
        "pdf_data=clean_text(extractedInformation).split()\n",
        "my_file = open(r'/content/my_keywords.txt',\"r\")\n",
        "k = my_file.read().split()\n",
        "k = set(k)\n",
        "dict_keywords={}\n",
        "        \n",
        "for i in k:\n",
        "  dict_keywords[i]=0\n",
        "        \n",
        "for i in dict_keywords:\n",
        "  if i in pdf_data:\n",
        "    dict_keywords[i]+=1\n",
        "print(km.predict([[returnSum(dict_keywords,my_weights),1]]))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "owybiuAQrh66",
        "outputId": "247a32a2-4ef8-4e76-d71c-a988830169fb"
      },
      "source": [
        "!pip install anvil-uplink"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting anvil-uplink\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/65/776713490bfd5145ddb87834355bf7936bd233b273098e37dc12f1ac253c/anvil_uplink-0.3.36-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.4MB/s \n",
            "\u001b[?25hCollecting ws4py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/20/4019a739b2eefe9282d3822ef6a225250af964b117356971bd55e274193c/ws4py-0.5.1.tar.gz (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.15.0)\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Building wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-cp37-none-any.whl size=45230 sha256=15c8dedfd6eec4e0ed6a38fce37c065a00c12222390439616e3c1864c278e009\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/6e/4e/8b0ae12fb9b8a05715256952cf7609a8ab86285fab99b88c68\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.3.36 argparse-1.4.0 ws4py-0.5.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ceJph_snsRi",
        "outputId": "4b45026d-0439-4853-a94e-cfb84fa04aae"
      },
      "source": [
        "import anvil.server\n",
        "\n",
        "anvil.server.connect(\"67I3HBH3UKSH7SJCJQIOGLNQ-GERJTPAN4PQB24X3\")\n",
        "\n",
        "@anvil.server.callable\n",
        "def say_hello(image):\n",
        "  \n",
        "  decodeit = open('input.jpeg', 'wb')\n",
        "  decodeit.write(base64.b64decode((image)))\n",
        "  decodeit.close()\n",
        "  img_path='/content/input.jpeg'\n",
        "  extractedInformation = pytesseract.image_to_string(Image.open(img_path))\n",
        "  pdf_data=clean_text(extractedInformation).split()\n",
        "  my_file = open(r'/content/my_keywords.txt',\"r\")\n",
        "  k = my_file.read().split()\n",
        "  k = set(k)\n",
        "  dict_keywords={}\n",
        "  for i in k:\n",
        "    dict_keywords[i]=0\n",
        "        \n",
        "  for i in dict_keywords:\n",
        "    if i in pdf_data:\n",
        "      dict_keywords[i]+=1\n",
        "  m=(km.predict([[returnSum(dict_keywords,my_weights),1]]))\n",
        "  if m==[flag]:\n",
        "    return \"Invalid\"\n",
        "  return \"Valid\"\n",
        "\n",
        "\n",
        "anvil.server.wait_forever()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default environment (dev)\" as SERVER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNBy9Gls0Fwi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}